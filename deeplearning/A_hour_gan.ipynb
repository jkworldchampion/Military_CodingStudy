{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIjEQRiwVMaMNwqaGCoruB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkworldchampion/Military_CodingStudy/blob/main/deeplearning/A_hour_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 간단한 코드로 gan의 구조 살펴보기\n",
        "다음은 Gan의 핵심인 Discriminator와 Generator가 어떻게 구성되어 있는지 가볍게 알아볼 수 있는 코드이다."
      ],
      "metadata": {
        "id": "5pqf1kNuGfxV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nps-bkmG8gp5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 판별기 생성\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(784, 128),   # 입력 28*28, hidden 128\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# 생성기 생성\n",
        "G = nn.Sequential(\n",
        "    nn.Linear(100, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 784),\n",
        "    nn.Tanh()\n",
        ")\n",
        "\n",
        "# loss함수 정의\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# optimizer 설정\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.01)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.01)\n",
        "\n",
        "# 입력값에 대한 가정\n",
        "# Assume x be real images of shape (batch_size, 784)\n",
        "# Asuume z be random nois of shape (batch_size, 100)\n",
        "\n",
        "# train\n",
        "while True:\n",
        "    # train D\n",
        "    loss = criterion(D(x), 1) + criterion(D(G(z)), 0)\n",
        "    loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    # train G\n",
        "    loss = criterion(D(G(z)), 1)\n",
        "    loss.backward()\n",
        "    g_optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실행이 되는 gan코드!!"
      ],
      "metadata": {
        "id": "VT2v0pS2GjK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요 library 불러오기"
      ],
      "metadata": {
        "id": "KCYEH35u6Uit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "aI2gSAEG6Sqk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gpu 설정과 Hyper-parameter 설정해주기"
      ],
      "metadata": {
        "id": "MN79Ns9964hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "# torch.device('cuda') or ('cpu')로 device설정\n",
        "# torch.cuda.is_available()로 cuda 가능한지 확인\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # cuda.is\n",
        "\n",
        "# Hyper-parameters\n",
        "latent_size = 64   # 생성기 G를 최적화시키기 위해 적절하게 큰 latent space의 크기를 결정하는 값. 결국 가장 중요한 값.\n",
        "hidden_size = 256  \n",
        "image_size = 784   # input의 28*28\n",
        "num_epochs = 200\n",
        "batch_size = 100\n",
        "sample_dir = 'samples'"
      ],
      "metadata": {
        "id": "GK94cnfO6XC2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data 불러오기(다운로드) 및 기본 설정"
      ],
      "metadata": {
        "id": "6-55oOEx8Yat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory if not exists\n",
        "if not os.path.exists(sample_dir):  # 현재 경로에 samples 파일이 없으면\n",
        "    os.makedirs(sample_dir)         # samples 파일을 만들어라\n",
        "\n",
        "# Image processing\n",
        "transform = transforms.Compose([  \n",
        "    transforms.ToTensor(),             # numpy 이미지에서 torch 이미지로 변경\n",
        "    transforms.Normalize(mean=[0.5],   # 1 for greyscale channels\n",
        "                         std=[0.5])    # normailze는 (image - mean / std)를 수행함. 즉, 정규화 시키기\n",
        "])\n",
        "\n",
        "# MNIST dataset\n",
        "mnist = torchvision.datasets.MNIST(root='/data',   # 경로 설정\n",
        "                                   train=True,     # train용 데이터를 가져올지, test용인지. True일 경우 train용 데이터\n",
        "                                   transform=transform,  # 이미지를 가져올 형태\n",
        "                                   download=True)  # mnist가 없으면 다운로드 한다\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist,  # 어떤 데이터를 가져오는가\n",
        "                                          batch_size=batch_size,  # batch_size\n",
        "                                          shuffle=True)   # 섞을것인지"
      ],
      "metadata": {
        "id": "ep7JDc6U8dQ1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_loader에서 간단하게 데이터 살펴보기\n",
        "import matplotlib.pyplot as plt\n",
        "for data in data_loader:\n",
        "  now_image = data[0][0]\n",
        "  tran = transforms.ToPILImage()\n",
        "  img_t = tran(now_image)\n",
        "  plt.imshow(img_t)\n",
        "  print(data[1][0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "C64NUBkc92bL",
        "outputId": "a80bde8f-264e-45cc-cea0-852af45f286e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator와 Generator build"
      ],
      "metadata": {
        "id": "75TAD2sh8rGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator   \n",
        "'''\n",
        "D는 판별기로써 결국 진짜를 1로, 가짜를 0으로 판별해야함 결과치는 softmax이므로 0~1에 해당함 \n",
        "'''\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(image_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Generator\n",
        "'''\n",
        "G는 생성기로써 진짜같은 이미지를 생성해 내야함, 즉 D(G(x)) = 1로 가까워져야함.\n",
        "'''\n",
        "G = nn.Sequential(\n",
        "    nn.Linear(latent_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, image_size),\n",
        "    nn.Tanh()\n",
        ")\n",
        "\n",
        "# Device setting  \n",
        "D = D.to(device)   # Gpu로 설정\n",
        "G = G.to(device)"
      ],
      "metadata": {
        "id": "zEdEBeRN8xbI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function설정과 Optimizer 설정"
      ],
      "metadata": {
        "id": "9JGswgfG84qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary cross entropy loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)     # D:G를 1:5정도로 해봤는데 매우 망했다.\n",
        "\n",
        "# 사진 저장시 필요한 denormalization function\n",
        "def denorm(x):     \n",
        "    out = (x+1) / 2\n",
        "    return out.clamp(0, 1)   \n",
        "\n",
        "# iteration마다 gradient를 초기화 해주기 위한 function\n",
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()   # pytorch는 gradient가 누적되기 때문에 다시 0으로 만들어 줘야한다.\n",
        "    g_optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "dJBNWIsW84BR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습하기와 결과물 저장하기"
      ],
      "metadata": {
        "id": "LmKE-Gaa9hcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "total_step = len(data_loader)  # 600\n",
        "for epoch in range(num_epochs):  # 주어진 epochs만큼 돌리기\n",
        "    for i, (images, _) in enumerate(data_loader):  # data_loader에서 iterator 객체를 받아와 하나씩 다룬다. 정확히는 batch_size만큼 matrix로 가져온다, 정답에 해당하는 tensor배열은 _로 버린다\n",
        "        images = images.reshape(batch_size, -1).to(device)   # (100, 1, 28, 28) -> (100, 784)\n",
        "\n",
        "        # Create the labels which are later used as input for the BCE loss\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)    # (100, 1)의 1로된 tensor / 결국 D가 진짜 이미지를 1로 판별해야하기 때문\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)   # (100, 1)의 0으로 된 tensor\n",
        "\n",
        "        #===========================#\n",
        "        #  Train the discriminator  # \n",
        "        #===========================#\n",
        "\n",
        "        # Compute BCE_Loss using real images where BCE_Loss(x, y): -y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "        # Second term of the loss is always zero since real_label == 1\n",
        "        outputs = D(images)                             # outputs.shape = (batch_size, 1), 각각 진짜일 sigmoid값 \n",
        "        d_loss_real = criterion(outputs, real_labels)   # 진짜일 확률을 예측한 값과 1 사이의 Binary_Cross_Entropy값 0.67\n",
        "        real_score = outputs\n",
        "\n",
        "        # Compute BCELoss using fake images\n",
        "        # First term of the loss is always zero since fake_labels == 0\n",
        "        z = torch.randn(batch_size, latent_size).to(device)   # latent_size를 통해 잠재 공간의 크기를 정한 뒤 이미지에서 특징을 매칭시킬 z를 정의한다.\n",
        "        fake_images = G(z)                                    # z를 통해 fake_image를 생성한다  \n",
        "        \n",
        "        # 생성된 이미지를 볼 수 있다!!\n",
        "        # tran = transforms.ToPILImage()\n",
        "        # img_t = tran(fake_images[0].reshape(28,28))\n",
        "        # plt.imshow(img_t)\n",
        "\n",
        "        outputs = D(fake_images)   # fake_image에 대한 진실 판별값을 알아본다\n",
        "        d_loss_fake = criterion(outputs, fake_labels)  # BCELoss를 구한다\n",
        "        fake_score = outputs\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        reset_grad()  \n",
        "        d_loss.backward()   # 스칼라 값에 대해 미분을 시행한다\n",
        "        d_optimizer.step()  # 미분값을 토대로 parameters를 갱신한다\n",
        "        \n",
        "        # ================================================================== #\n",
        "        #                        Train the generator                         #\n",
        "        # ================================================================== #\n",
        "\n",
        "        # Compute loss with fake images\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)   # D(G(z))\n",
        "        \n",
        "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
        "        g_loss = criterion(outputs, real_labels)    # 결국 D(G(z))가 1로 가까워져야하기 때문\n",
        "        \n",
        "        # Backprop and optimize\n",
        "        reset_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        if (i+1) % 300 == 0:    # batch_size에 의해 iterator가 3번 돌면, 즉 데이터가 반이 계산되면 다음을 출력\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
        "                          real_score.mean().item(), fake_score.mean().item()))\n",
        "    \n",
        "    # Save real images\n",
        "    if (epoch+1) == 1:\n",
        "        images = images.reshape(images.size(0), 1, 28, 28)\n",
        "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "    # Save sampled images\n",
        "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))"
      ],
      "metadata": {
        "id": "Nbk6TTpu9l55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 저장하기"
      ],
      "metadata": {
        "id": "pHzP-igF9p7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model checkpoints \n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ],
      "metadata": {
        "id": "MhJdnd_p9sQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}