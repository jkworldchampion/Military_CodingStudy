{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "computer_vision_tf2_ch4_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4BdDxfp+Vh31JTfyw001z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkworldchampion/Military_CodingStudy/blob/main/deeplearning/computer_vision_tf2_ch4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NoteBook 1 : Implementing ResNet from Scratch"
      ],
      "metadata": {
        "id": "EneFioIPMdyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 노트에서는 ResNet을 다룰 것이다. CNN을 재사용하고 18에서 152계층의 모듈 방식을 구현해 연구가 얼마나 멀리까지 왔는지 알아볼 것이다."
      ],
      "metadata": {
        "id": "XKuhR7KYMub2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hLKgCC4gMTWu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "# Choosing which GPU this notebook can access\n",
        "# (useful when running multiple experiments in parallel, on different GPUs):\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\" "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비하기\n",
        "CIFAR-10과 CIFAR-100은 유명한 데이터셋이다. 처음 데이터는 60000개의 32*32의 10classes의 데이터셋이고, 그 다음은 60000개의 32*32, 100classes의 데이터이다. 이번 노트북에서 우리는 CIFAR-100을 사용할 것이다"
      ],
      "metadata": {
        "id": "F6F_rQFFxrBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow-Datasets\n",
        "다른 데이터셋들과 같이  CIFAR-100은 알고리즘 연구자들에게 많이 사용되고 있다.  \n",
        "연구자와 아마추어를 돕기위해 Tensorflow team은 `tensorflow_datasets`패키지를 준비했다. "
      ],
      "metadata": {
        "id": "YUPnRP-nyYNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.list_builders()[0:40:4]  # 준비된 데이터셋이 많다. 10개만 보자."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "739VKefSNASM",
        "outputId": "e4effa75-9f97-497f-faf2-aecad4389b7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abstract_reasoning',\n",
              " 'ag_news_subset',\n",
              " 'anli',\n",
              " 'beans',\n",
              " 'binarized_mnist',\n",
              " 'c4',\n",
              " 'cars196',\n",
              " 'celeb_a_hq',\n",
              " 'cifar100',\n",
              " 'cityscapes']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "디테일한 리스트는 :https://www.tensorflow.org/datasets/datasets. 여기서 볼 수 있다.  \n",
        "  \n",
        "여기서 `\"cifar100\"`을 선택할 것이다, 다운로드 한뒤 메타정보를 확인해보자"
      ],
      "metadata": {
        "id": "g977f099z5tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_builder = tfds.builder(\"cifar100\")\n",
        "cifar_builder.download_and_prepare()    # 이것의 역할이 뭐지??\n",
        "\n",
        "print(cifar_builder.info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcq4OpRMPKsm",
        "outputId": "74e56d4b-ca5b-41f8-91e0-0ac4d63e2b9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='cifar100',\n",
            "    version=3.0.2,\n",
            "    description='This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).',\n",
            "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
            "    features=FeaturesDict({\n",
            "        'coarse_label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),\n",
            "        'id': Text(shape=(), dtype=tf.string),\n",
            "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=100),\n",
            "    }),\n",
            "    total_num_examples=60000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 50000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
            "        author = {Alex Krizhevsky},\n",
            "        title = {Learning multiple layers of features from tiny images},\n",
            "        institution = {},\n",
            "        year = {2009}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow-Datasets는 유용한 몇가지 정보를 제공해준다, sample numbers, types, sizes, 그리고 dataset desciription 등등  \n",
        "  \n",
        "또한 class name에도 접근할 수 있다:"
      ],
      "metadata": {
        "id": "2CO2V7gK0Ote"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cifar_builder.info.features[\"label\"].names)\n",
        "print(len(cifar_builder.info.features[\"label\"].names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UHeiZ3GPMlP",
        "outputId": "6249bf68-4f10-4c26-d318-3dff5540325f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "메타 데이터에서 볼 수 있듯이, CIFAR-100은 20개의  super classes로 분류할 수 있다."
      ],
      "metadata": {
        "id": "vyAQ3NQC3KMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(cifar_builder.info.features[\"coarse_label\"].names)\n",
        "print(len(cifar_builder.info.features[\"coarse_label\"].names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJEdYvnxPaJY",
        "outputId": "28545f29-3ce9-463a-829a-36b72097cabd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aquatic_mammals', 'fish', 'flowers', 'food_containers', 'fruit_and_vegetables', 'household_electrical_devices', 'household_furniture', 'insects', 'large_carnivores', 'large_man-made_outdoor_things', 'large_natural_outdoor_scenes', 'large_omnivores_and_herbivores', 'medium_mammals', 'non-insect_invertebrates', 'people', 'reptiles', 'small_mammals', 'trees', 'vehicles_1', 'vehicles_2']\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "하지만, 실험을 위해 100개의 classes를 고수할 것이다."
      ],
      "metadata": {
        "id": "qC_2y2bM3TKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Pipeline Preparation\n",
        "학습하고 시험할 데이터가 있다. 그리고 이제 PipeLine을 정의해보자."
      ],
      "metadata": {
        "id": "w8wHJFZM3fQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Some hyper-parameters:\n",
        "input_shape = [224, 224, 3] # 이러한 모양으로 resize할 것이다\n",
        "batch_size  = 16            # Images per batch (컴퓨터의 capability에 맞게 reduce/increase하자)\n",
        "num_epochs  = 100           # Max number of training epochs\n",
        "\n",
        "# Train/val Datasets:\n",
        "train_cifar_dataset = cifar_builder.as_dataset(split=tfds.Split.TRAIN)\n",
        "val_cifar_dataset = cifar_builder.as_dataset(split=tfds.Split.TEST)\n",
        "\n",
        "# Number of classes:\n",
        "num_classes = cifar_builder.info.features['label'].num_classes  # 여기선 100개\n",
        "\n",
        "# Number of images:\n",
        "num_train_imgs = cifar_builder.info.splits['train'].num_examples  # train 데이터셋의 개수 50000\n",
        "num_val_imgs = cifar_builder.info.splits['test'].num_examples     # test 데이터셋의 개수 10000"
      ],
      "metadata": {
        "id": "TVPxU3xvPay_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training dataset instance: {}'.format(train_cifar_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBSvZUAUPddw",
        "outputId": "0fb82132-9dc8-4dec-9fea-6db7864fef40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset instance: <PrefetchDataset element_spec={'coarse_label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'id': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data는 TensorFlow-Datasets 모듈에 의해 `tf.data.Dataset` 인스턴스로 제공된다.  \n",
        "  \n",
        "7장은 tf.data API의 효율적인 입력과 파이프라인 작성에 대한 내용이므로 자세히 설명하지는 않겠다. "
      ],
      "metadata": {
        "id": "7sRHRFN_jlZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_cifar_dataset = train_cifar_dataset.repeat(num_epochs).shuffle(10000)"
      ],
      "metadata": {
        "id": "ugko_41GPe0w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 셋을 만들때 사용하는 방법이다. `.repeat(n)`는 데이터를 n만큼 반복한다. `.shuffle(n)`은 buffer_size가 n만큼으로, n만큼 중 랜덤하게 뽑는다. 따라서 데이터가 랜덤하게 생성된다고 할 수 있다."
      ],
      "metadata": {
        "id": "5DLm_oU03lMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _prepare_data_fn(features, input_shape, augment=False):\n",
        "    \"\"\"\n",
        "    Resize image to expected dimensions, and opt. apply some random transformations.\n",
        "    :param features:    Data\n",
        "    :param input_shape: Shape expected by the models (images will be resized accordingly)\n",
        "    :param augment:     Flag to apply some random augmentations to the images\n",
        "    :return:            Augmented Images, Labels\n",
        "    \"\"\"\n",
        "    input_shape = tf.convert_to_tensor(input_shape)\n",
        "    \n",
        "    # Tensorflow-Dataset은 Estimator에서 기대된 feature dictionaries로 배치를 반환한다 \n",
        "    # Keras models를 훈련시키기 위해, batch content를 tuple로 반환하는 것이 중요하다\n",
        "    image = features['image']\n",
        "    label = features['label']\n",
        "    # 이미지를 float type으로 바꾼다, 또한 scaling도 한다 [0, 255]dptj [0., 1.]로\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    \n",
        "    if augment:\n",
        "        # Randomly applied horizontal flip:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "        # Random B/S changes:\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "        image = tf.clip_by_value(image, 0.0, 1.0) # keeping pixel values in check\n",
        "\n",
        "        # Random resize and random crop back to expected size:\n",
        "        \n",
        "        random_scale_factor = tf.random.uniform([1], minval=1., maxval=1.4, dtype=tf.float32)\n",
        "        scaled_height = tf.cast(tf.cast(input_shape[0], tf.float32) * random_scale_factor, \n",
        "                                tf.int32)\n",
        "        scaled_width = tf.cast(tf.cast(input_shape[1], tf.float32) * random_scale_factor, \n",
        "                               tf.int32)\n",
        "        scaled_shape = tf.squeeze(tf.stack([scaled_height, scaled_width]))\n",
        "        image = tf.image.resize(image, scaled_shape)\n",
        "        image = tf.image.random_crop(image, input_shape)\n",
        "    else:\n",
        "        image = tf.image.resize(image, input_shape[:2])\n",
        "        \n",
        "    return image, label"
      ],
      "metadata": {
        "id": "ZwjuFgu7Pggl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "prepare_data_fn_for_train = functools.partial(_prepare_data_fn, \n",
        "                                              input_shape=input_shape,\n",
        "                                              augment=True)\n",
        "\n",
        "train_cifar_dataset = train_cifar_dataset.map(prepare_data_fn_for_train, num_parallel_calls=4)\n",
        "\n",
        "# We also ask the dataset to batch the samples:\n",
        "train_cifar_dataset = train_cifar_dataset.batch(batch_size)\n",
        "\n",
        "train_cifar_dataset = train_cifar_dataset.prefetch(1) # improve time performance c.f. Chapter 7"
      ],
      "metadata": {
        "id": "0UHk4PB3PjpU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "비슷하게 평가에 사용할 데이터셋도 준비한다(shuffling과 augmenting은 안한다)"
      ],
      "metadata": {
        "id": "thZXKQrP9aaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_data_fn_for_val = functools.partial(_prepare_data_fn, \n",
        "                                              input_shape=input_shape,\n",
        "                                              augment=False)\n",
        "\n",
        "val_cifar_dataset = (val_cifar_dataset\n",
        "                     .repeat()\n",
        "                     .map(prepare_data_fn_for_val, num_parallel_calls=4)\n",
        "                     .batch(batch_size)\n",
        "                     .prefetch(1))"
      ],
      "metadata": {
        "id": "ZpZoRHoiPlAj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 훈련시킬 준비가 끝이났다.  \n",
        "  \n",
        "이러한 objects는 Keras의 `model.fit()`메서드와 호환이 된다. 하지만 잘 작동하려면 적절한 epochs와 step_per_epoch, validation_steps를 잘 지정해야한다. "
      ],
      "metadata": {
        "id": "7s4WTpbu95Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps_per_epoch = math.ceil(num_train_imgs / batch_size)  # 올림하여 정수를 반환\n",
        "val_steps_per_epoch   = math.ceil(num_val_imgs / batch_size)"
      ],
      "metadata": {
        "id": "F50QqLtCPmSD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing ResNet with Keras\n"
      ],
      "metadata": {
        "id": "4sraFj2j_kCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Activation, Dense, Flatten, Conv2D, MaxPooling2D, \n",
        "    GlobalAveragePooling2D, AveragePooling2D, BatchNormalization, add)\n",
        "import tensorflow.keras.regularizers as regulizers"
      ],
      "metadata": {
        "id": "T5ahSDFQPn88"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다양한 크기의 네트워크를 생성할 수 있는 model-bulider 기능을 구현하기 위해서는 ResNet구현을 모듈화해야한다. 따라서 ResNet의 주요 구성요소인 residual blocks를 모듈 방식으로 구현할 것이다. \n",
        "  \n",
        "  - 3*3 conv를 입력에 적용한 후 배치 정규화 및 ReLU활성화\n",
        "  - 하나의 바로가는 branch, 수정없이 바로 적용하거나 다른 branch에서 입력 volume이 변경된 경우 1*1의 conv만 적용하여 입력볼륨 조정\n",
        "  - 하나의 병합 operation, 두 개의 branchㅇ의 값을 더하는 작업  \n",
        "    \n",
        "이제 우리는 `conv-batchnorm-relu`의 층을 갖는 stack을 만들 것이다."
      ],
      "metadata": {
        "id": "W93yoXQV_6ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the Residual Blocks"
      ],
      "metadata": {
        "id": "Iqtr0NzUDkV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _res_conv(filters, kernel_size=3, padding='same', strides=1, use_relu=True, use_bias=False, name='cbr',\n",
        "              kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Return a layer block chaining conv, batchnrom and reLU activation.\n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param padding:                 Convolution padding.\n",
        "    :param strides:                 Convolution strides.\n",
        "    :param use_relu:                Flag to apply ReLu activation at the end.\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param name:                    Name suffix for the layers.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        conv = Conv2D(\n",
        "            filters=filters, kernel_size=kernel_size, padding=padding, strides=strides, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, \n",
        "            name=name + '_c')(x)\n",
        "        res = BatchNormalization(axis=-1, name=name + '_bn')(conv)\n",
        "        if use_relu:\n",
        "            res = Activation(\"relu\", name=name + '_r')(res)\n",
        "        return res\n",
        "\n",
        "    return layer_fn"
      ],
      "metadata": {
        "id": "28n23cK7PpFk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _merge_with_shortcut(kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4), \n",
        "                         name='block'):\n",
        "    \"\"\"\n",
        "    Return a layer block which merge an input tensor and the corresponding \n",
        "    residual output tensor from another branch.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :param name:                    Name suffix for the layers.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x, x_residual):\n",
        "        # We check if `x_residual` was scaled down. If so, we scale `x` accordingly with a 1x1 conv:\n",
        "        x_shape = tf.keras.backend.int_shape(x)\n",
        "        x_residual_shape = tf.keras.backend.int_shape(x_residual)\n",
        "        if x_shape == x_residual_shape:\n",
        "            shortcut = x\n",
        "        else:\n",
        "            strides = (\n",
        "                int(round(x_shape[1] / x_residual_shape[1])), # vertical stride\n",
        "                int(round(x_shape[2] / x_residual_shape[2]))  # horizontal stride\n",
        "            )\n",
        "            x_residual_channels = x_residual_shape[3]\n",
        "            shortcut = Conv2D(\n",
        "                filters=x_residual_channels, kernel_size=(1, 1), padding=\"valid\", strides=strides,\n",
        "                kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "                name=name + '_shortcut_c')(x)\n",
        "\n",
        "        merge = add([shortcut, x_residual])\n",
        "        return merge\n",
        "\n",
        "    return layer_fn"
      ],
      "metadata": {
        "id": "SLDdd5YwPqtt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _residual_block_basic(filters, kernel_size=3, strides=1, use_bias=False, name='res_basic',\n",
        "                          kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Return a basic residual layer block.\n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param strides:                 Convolution strides\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        x_conv1 = _res_conv(\n",
        "            filters=filters, kernel_size=kernel_size, padding='same', strides=strides, \n",
        "            use_relu=True, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_cbr_1')(x)\n",
        "        x_residual = _res_conv(\n",
        "            filters=filters, kernel_size=kernel_size, padding='same', strides=1, \n",
        "            use_relu=False, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_cbr_2')(x_conv1)\n",
        "        merge = _merge_with_shortcut(kernel_initializer, kernel_regularizer,name=name)(x, x_residual)\n",
        "        merge = Activation('relu')(merge)\n",
        "        return merge\n",
        "\n",
        "    return layer_fn"
      ],
      "metadata": {
        "id": "YwWah6o8PsUE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _residual_block_bottleneck(filters, kernel_size=3, strides=1, use_bias=False, name='res_bottleneck',\n",
        "                               kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Return a residual layer block with bottleneck, recommended for deep ResNets (depth > 34).\n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param strides:                 Convolution strides\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        x_bottleneck = _res_conv(\n",
        "            filters=filters, kernel_size=1, padding='valid', strides=strides, \n",
        "            use_relu=True, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_cbr1')(x)\n",
        "        x_conv = _res_conv(\n",
        "            filters=filters, kernel_size=kernel_size, padding='same', strides=1, \n",
        "            use_relu=True, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_cbr2')(x_bottleneck)\n",
        "        x_residual = _res_conv(\n",
        "            filters=filters * 4, kernel_size=1, padding='valid', strides=1, \n",
        "            use_relu=False, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "            name=name + '_cbr3')(x_conv)\n",
        "        merge = _merge_with_shortcut(kernel_initializer, kernel_regularizer, name=name)(x, x_residual)\n",
        "        merge = Activation('relu')(merge)\n",
        "        return merge\n",
        "\n",
        "    return layer_fn"
      ],
      "metadata": {
        "id": "P-2Ra7QRPt47"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chaining Blocks into Modular Networks"
      ],
      "metadata": {
        "id": "EXN94kgaC7IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _residual_macroblock(block_fn, filters, repetitions=3, kernel_size=3, strides_1st_block=1, use_bias=False,\n",
        "                         kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4),\n",
        "                         name='res_macroblock'):\n",
        "    \"\"\"\n",
        "    Return a layer block, composed of a repetition of `N` residual blocks.\n",
        "    :param block_fn:                Block layer method to be used.\n",
        "    :param repetitions:             Number of times the block should be repeated inside.\n",
        "    :param filters:                 Number of filters.\n",
        "    :param kernel_size:             Kernel size.\n",
        "    :param strides_1st_block:       Convolution strides for the 1st block.\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        Callable layer block\n",
        "    \"\"\"\n",
        "\n",
        "    def layer_fn(x):\n",
        "        for i in range(repetitions):\n",
        "            block_name = \"{}_{}\".format(name, i) \n",
        "            strides = strides_1st_block if i == 0 else 1\n",
        "            x = block_fn(filters=filters, kernel_size=kernel_size, \n",
        "                         strides=strides, use_bias=use_bias,\n",
        "                         kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer,\n",
        "                         name=block_name)(x)\n",
        "        return x\n",
        "\n",
        "    return layer_fn"
      ],
      "metadata": {
        "id": "xqrtw5wIPvmE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet(input_shape, num_classes=1000, block_fn=_residual_block_basic, repetitions=(2, 2, 2, 2),\n",
        "           use_bias=False, kernel_initializer='he_normal', kernel_regularizer=regulizers.l2(1e-4)):\n",
        "    \"\"\"\n",
        "    Build a ResNet model for classification.\n",
        "    :param input_shape:             Input shape (e.g. (224, 224, 3))\n",
        "    :param num_classes:             Number of classes to predict\n",
        "    :param block_fn:                Block layer method to be used.\n",
        "    :param repetitions:             List of repetitions for each macro-blocks the network should contain.\n",
        "    :param use_bias:                Flag to use bias or not in Conv layer.\n",
        "    :param kernel_initializer:      Kernel initialisation method name.\n",
        "    :param kernel_regularizer:      Kernel regularizer.\n",
        "    :return:                        ResNet model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input and 1st layers:\n",
        "    inputs = Input(shape=input_shape)\n",
        "    conv = _res_conv(\n",
        "        filters=64, kernel_size=7, strides=2, use_relu=True, use_bias=use_bias,\n",
        "        kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(inputs)\n",
        "    maxpool = MaxPooling2D(pool_size=3, strides=2, padding='same')(conv)\n",
        "\n",
        "    # Chain of residual blocks:\n",
        "    filters = 64\n",
        "    strides = 2\n",
        "    res_block = maxpool\n",
        "    for i, repet in enumerate(repetitions):\n",
        "        # We do not further reduce the input size for the 1st block (max-pool applied just before):\n",
        "        block_strides = strides if i != 0 else 1\n",
        "        macroblock_name = \"block_{}\".format(i) \n",
        "        res_block = _residual_macroblock(\n",
        "            block_fn=block_fn, repetitions=repet, name=macroblock_name,\n",
        "            filters=filters, strides_1st_block=block_strides, use_bias=use_bias,\n",
        "            kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)(res_block)\n",
        "        filters = min(filters * 2, 1024) # we limit to 1024 filters max\n",
        "\n",
        "    # Final layers for prediction:\n",
        "    res_spatial_dim = tf.keras.backend.int_shape(res_block)[1:3]\n",
        "    avg_pool = AveragePooling2D(pool_size=res_spatial_dim, strides=1)(res_block)\n",
        "    flatten = Flatten()(avg_pool)\n",
        "    predictions = Dense(units=num_classes, kernel_initializer=kernel_initializer, \n",
        "                        activation='softmax')(flatten)\n",
        "\n",
        "    # Model:\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    return model"
      ],
      "metadata": {
        "id": "vuQYihemPxIL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet18(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_basic, repetitions=(2, 2, 2, 2),\n",
        "                  use_bias=use_bias, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet34(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_basic, repetitions=(3, 4, 6, 3),\n",
        "                  use_bias=use_bias, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet50(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    # Note: ResNet50 is similar to ResNet34,\n",
        "    # with the basic blocks replaced by bottleneck ones (3 conv layers each instead of 2)\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_bottleneck, repetitions=(3, 4, 6, 3),\n",
        "                  use_bias=use_bias, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet101(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_bottleneck, repetitions=(3, 4, 23, 3),\n",
        "                  use_bias=use_bias, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)\n",
        "\n",
        "\n",
        "def ResNet152(input_shape, num_classes=1000, use_bias=True,\n",
        "             kernel_initializer='he_normal', kernel_regularizer=None):\n",
        "    return ResNet(input_shape, num_classes, block_fn=_residual_block_bottleneck, repetitions=(3, 8, 36, 3),\n",
        "                  use_bias=use_bias, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer)"
      ],
      "metadata": {
        "id": "METylOrmPy0r"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstrating with ResNet-50"
      ],
      "metadata": {
        "id": "kITUH2AcDKVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = ResNet50(input_shape=input_shape, num_classes=num_classes)\n",
        "resnet50.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da-e9G42P1Ad",
        "outputId": "9f42fdab-9fb4-4a8c-881a-ab5aa20a4b08"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " cbr_c (Conv2D)                 (None, 112, 112, 64  9472        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " cbr_bn (BatchNormalization)    (None, 112, 112, 64  256         ['cbr_c[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " cbr_r (Activation)             (None, 112, 112, 64  0           ['cbr_bn[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['cbr_r[0][0]']                  \n",
            "                                                                                                  \n",
            " block_0_0_cbr1_c (Conv2D)      (None, 56, 56, 64)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " block_0_0_cbr1_bn (BatchNormal  (None, 56, 56, 64)  256         ['block_0_0_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_0_0_cbr1_r (Activation)  (None, 56, 56, 64)   0           ['block_0_0_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_0_0_cbr2_c (Conv2D)      (None, 56, 56, 64)   36928       ['block_0_0_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_0_0_cbr2_bn (BatchNormal  (None, 56, 56, 64)  256         ['block_0_0_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_0_0_cbr2_r (Activation)  (None, 56, 56, 64)   0           ['block_0_0_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_0_0_cbr3_c (Conv2D)      (None, 56, 56, 256)  16640       ['block_0_0_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_0_0_shortcut_c (Conv2D)  (None, 56, 56, 256)  16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " block_0_0_cbr3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['block_0_0_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 56, 56, 256)  0           ['block_0_0_shortcut_c[0][0]',   \n",
            "                                                                  'block_0_0_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 56, 56, 256)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " block_0_1_cbr1_c (Conv2D)      (None, 56, 56, 64)   16448       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " block_0_1_cbr1_bn (BatchNormal  (None, 56, 56, 64)  256         ['block_0_1_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_0_1_cbr1_r (Activation)  (None, 56, 56, 64)   0           ['block_0_1_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_0_1_cbr2_c (Conv2D)      (None, 56, 56, 64)   36928       ['block_0_1_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_0_1_cbr2_bn (BatchNormal  (None, 56, 56, 64)  256         ['block_0_1_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_0_1_cbr2_r (Activation)  (None, 56, 56, 64)   0           ['block_0_1_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_0_1_cbr3_c (Conv2D)      (None, 56, 56, 256)  16640       ['block_0_1_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_0_1_cbr3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['block_0_1_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 56, 56, 256)  0           ['activation[0][0]',             \n",
            "                                                                  'block_0_1_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 56, 56, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " block_0_2_cbr1_c (Conv2D)      (None, 56, 56, 64)   16448       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " block_0_2_cbr1_bn (BatchNormal  (None, 56, 56, 64)  256         ['block_0_2_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_0_2_cbr1_r (Activation)  (None, 56, 56, 64)   0           ['block_0_2_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_0_2_cbr2_c (Conv2D)      (None, 56, 56, 64)   36928       ['block_0_2_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_0_2_cbr2_bn (BatchNormal  (None, 56, 56, 64)  256         ['block_0_2_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_0_2_cbr2_r (Activation)  (None, 56, 56, 64)   0           ['block_0_2_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_0_2_cbr3_c (Conv2D)      (None, 56, 56, 256)  16640       ['block_0_2_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_0_2_cbr3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['block_0_2_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 56, 56, 256)  0           ['activation_1[0][0]',           \n",
            "                                                                  'block_0_2_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 56, 56, 256)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " block_1_0_cbr1_c (Conv2D)      (None, 28, 28, 128)  32896       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " block_1_0_cbr1_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_0_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_0_cbr1_r (Activation)  (None, 28, 28, 128)  0           ['block_1_0_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_0_cbr2_c (Conv2D)      (None, 28, 28, 128)  147584      ['block_1_0_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_0_cbr2_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_0_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_0_cbr2_r (Activation)  (None, 28, 28, 128)  0           ['block_1_0_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_0_cbr3_c (Conv2D)      (None, 28, 28, 512)  66048       ['block_1_0_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_0_shortcut_c (Conv2D)  (None, 28, 28, 512)  131584      ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " block_1_0_cbr3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['block_1_0_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 28, 28, 512)  0           ['block_1_0_shortcut_c[0][0]',   \n",
            "                                                                  'block_1_0_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 28, 28, 512)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " block_1_1_cbr1_c (Conv2D)      (None, 28, 28, 128)  65664       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " block_1_1_cbr1_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_1_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_1_cbr1_r (Activation)  (None, 28, 28, 128)  0           ['block_1_1_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_1_cbr2_c (Conv2D)      (None, 28, 28, 128)  147584      ['block_1_1_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_1_cbr2_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_1_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_1_cbr2_r (Activation)  (None, 28, 28, 128)  0           ['block_1_1_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_1_cbr3_c (Conv2D)      (None, 28, 28, 512)  66048       ['block_1_1_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_1_cbr3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['block_1_1_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 28, 28, 512)  0           ['activation_3[0][0]',           \n",
            "                                                                  'block_1_1_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 28, 28, 512)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " block_1_2_cbr1_c (Conv2D)      (None, 28, 28, 128)  65664       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " block_1_2_cbr1_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_2_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_2_cbr1_r (Activation)  (None, 28, 28, 128)  0           ['block_1_2_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_2_cbr2_c (Conv2D)      (None, 28, 28, 128)  147584      ['block_1_2_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_2_cbr2_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_2_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_2_cbr2_r (Activation)  (None, 28, 28, 128)  0           ['block_1_2_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_2_cbr3_c (Conv2D)      (None, 28, 28, 512)  66048       ['block_1_2_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_2_cbr3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['block_1_2_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 28, 28, 512)  0           ['activation_4[0][0]',           \n",
            "                                                                  'block_1_2_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 28, 28, 512)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " block_1_3_cbr1_c (Conv2D)      (None, 28, 28, 128)  65664       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " block_1_3_cbr1_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_3_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_3_cbr1_r (Activation)  (None, 28, 28, 128)  0           ['block_1_3_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_3_cbr2_c (Conv2D)      (None, 28, 28, 128)  147584      ['block_1_3_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_3_cbr2_bn (BatchNormal  (None, 28, 28, 128)  512        ['block_1_3_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_3_cbr2_r (Activation)  (None, 28, 28, 128)  0           ['block_1_3_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_3_cbr3_c (Conv2D)      (None, 28, 28, 512)  66048       ['block_1_3_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_1_3_cbr3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['block_1_3_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 28, 28, 512)  0           ['activation_5[0][0]',           \n",
            "                                                                  'block_1_3_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 28, 28, 512)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " block_2_0_cbr1_c (Conv2D)      (None, 14, 14, 256)  131328      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " block_2_0_cbr1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_0_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_0_cbr1_r (Activation)  (None, 14, 14, 256)  0           ['block_2_0_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_0_cbr2_c (Conv2D)      (None, 14, 14, 256)  590080      ['block_2_0_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_2_0_cbr2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_0_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_0_cbr2_r (Activation)  (None, 14, 14, 256)  0           ['block_2_0_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_0_cbr3_c (Conv2D)      (None, 14, 14, 1024  263168      ['block_2_0_cbr2_r[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_0_shortcut_c (Conv2D)  (None, 14, 14, 1024  525312      ['activation_6[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_0_cbr3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['block_2_0_cbr3_c[0][0]']       \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 14, 14, 1024  0           ['block_2_0_shortcut_c[0][0]',   \n",
            "                                )                                 'block_2_0_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 14, 14, 1024  0           ['add_7[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_1_cbr1_c (Conv2D)      (None, 14, 14, 256)  262400      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " block_2_1_cbr1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_1_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_1_cbr1_r (Activation)  (None, 14, 14, 256)  0           ['block_2_1_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_1_cbr2_c (Conv2D)      (None, 14, 14, 256)  590080      ['block_2_1_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_2_1_cbr2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_1_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_1_cbr2_r (Activation)  (None, 14, 14, 256)  0           ['block_2_1_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_1_cbr3_c (Conv2D)      (None, 14, 14, 1024  263168      ['block_2_1_cbr2_r[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_1_cbr3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['block_2_1_cbr3_c[0][0]']       \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 14, 14, 1024  0           ['activation_7[0][0]',           \n",
            "                                )                                 'block_2_1_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 14, 14, 1024  0           ['add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_2_cbr1_c (Conv2D)      (None, 14, 14, 256)  262400      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " block_2_2_cbr1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_2_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_2_cbr1_r (Activation)  (None, 14, 14, 256)  0           ['block_2_2_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_2_cbr2_c (Conv2D)      (None, 14, 14, 256)  590080      ['block_2_2_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_2_2_cbr2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_2_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_2_cbr2_r (Activation)  (None, 14, 14, 256)  0           ['block_2_2_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_2_cbr3_c (Conv2D)      (None, 14, 14, 1024  263168      ['block_2_2_cbr2_r[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_2_cbr3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['block_2_2_cbr3_c[0][0]']       \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 14, 14, 1024  0           ['activation_8[0][0]',           \n",
            "                                )                                 'block_2_2_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 14, 14, 1024  0           ['add_9[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_3_cbr1_c (Conv2D)      (None, 14, 14, 256)  262400      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " block_2_3_cbr1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_3_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_3_cbr1_r (Activation)  (None, 14, 14, 256)  0           ['block_2_3_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_3_cbr2_c (Conv2D)      (None, 14, 14, 256)  590080      ['block_2_3_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_2_3_cbr2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_3_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_3_cbr2_r (Activation)  (None, 14, 14, 256)  0           ['block_2_3_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_3_cbr3_c (Conv2D)      (None, 14, 14, 1024  263168      ['block_2_3_cbr2_r[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_3_cbr3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['block_2_3_cbr3_c[0][0]']       \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 14, 14, 1024  0           ['activation_9[0][0]',           \n",
            "                                )                                 'block_2_3_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 14, 14, 1024  0           ['add_10[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_4_cbr1_c (Conv2D)      (None, 14, 14, 256)  262400      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " block_2_4_cbr1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_4_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_4_cbr1_r (Activation)  (None, 14, 14, 256)  0           ['block_2_4_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_4_cbr2_c (Conv2D)      (None, 14, 14, 256)  590080      ['block_2_4_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_2_4_cbr2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_4_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_4_cbr2_r (Activation)  (None, 14, 14, 256)  0           ['block_2_4_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_4_cbr3_c (Conv2D)      (None, 14, 14, 1024  263168      ['block_2_4_cbr2_r[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_4_cbr3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['block_2_4_cbr3_c[0][0]']       \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 14, 14, 1024  0           ['activation_10[0][0]',          \n",
            "                                )                                 'block_2_4_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 14, 14, 1024  0           ['add_11[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_5_cbr1_c (Conv2D)      (None, 14, 14, 256)  262400      ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " block_2_5_cbr1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_5_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_5_cbr1_r (Activation)  (None, 14, 14, 256)  0           ['block_2_5_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_5_cbr2_c (Conv2D)      (None, 14, 14, 256)  590080      ['block_2_5_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_2_5_cbr2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['block_2_5_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_5_cbr2_r (Activation)  (None, 14, 14, 256)  0           ['block_2_5_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_5_cbr3_c (Conv2D)      (None, 14, 14, 1024  263168      ['block_2_5_cbr2_r[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_2_5_cbr3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['block_2_5_cbr3_c[0][0]']       \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 14, 14, 1024  0           ['activation_11[0][0]',          \n",
            "                                )                                 'block_2_5_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 14, 14, 1024  0           ['add_12[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_3_0_cbr1_c (Conv2D)      (None, 7, 7, 512)    524800      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " block_3_0_cbr1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['block_3_0_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_0_cbr1_r (Activation)  (None, 7, 7, 512)    0           ['block_3_0_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_0_cbr2_c (Conv2D)      (None, 7, 7, 512)    2359808     ['block_3_0_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_3_0_cbr2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['block_3_0_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_0_cbr2_r (Activation)  (None, 7, 7, 512)    0           ['block_3_0_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_0_cbr3_c (Conv2D)      (None, 7, 7, 2048)   1050624     ['block_3_0_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_3_0_shortcut_c (Conv2D)  (None, 7, 7, 2048)   2099200     ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " block_3_0_cbr3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['block_3_0_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 7, 7, 2048)   0           ['block_3_0_shortcut_c[0][0]',   \n",
            "                                                                  'block_3_0_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 7, 7, 2048)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " block_3_1_cbr1_c (Conv2D)      (None, 7, 7, 512)    1049088     ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " block_3_1_cbr1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['block_3_1_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_1_cbr1_r (Activation)  (None, 7, 7, 512)    0           ['block_3_1_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_1_cbr2_c (Conv2D)      (None, 7, 7, 512)    2359808     ['block_3_1_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_3_1_cbr2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['block_3_1_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_1_cbr2_r (Activation)  (None, 7, 7, 512)    0           ['block_3_1_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_1_cbr3_c (Conv2D)      (None, 7, 7, 2048)   1050624     ['block_3_1_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_3_1_cbr3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['block_3_1_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 7, 7, 2048)   0           ['activation_13[0][0]',          \n",
            "                                                                  'block_3_1_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 7, 7, 2048)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " block_3_2_cbr1_c (Conv2D)      (None, 7, 7, 512)    1049088     ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " block_3_2_cbr1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['block_3_2_cbr1_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_2_cbr1_r (Activation)  (None, 7, 7, 512)    0           ['block_3_2_cbr1_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_2_cbr2_c (Conv2D)      (None, 7, 7, 512)    2359808     ['block_3_2_cbr1_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_3_2_cbr2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['block_3_2_cbr2_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_2_cbr2_r (Activation)  (None, 7, 7, 512)    0           ['block_3_2_cbr2_bn[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_2_cbr3_c (Conv2D)      (None, 7, 7, 2048)   1050624     ['block_3_2_cbr2_r[0][0]']       \n",
            "                                                                                                  \n",
            " block_3_2_cbr3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['block_3_2_cbr3_c[0][0]']       \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 7, 7, 2048)   0           ['activation_14[0][0]',          \n",
            "                                                                  'block_3_2_cbr3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 7, 7, 2048)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_15[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          204900      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,777,252\n",
            "Trainable params: 23,731,812\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying Images with ResNet"
      ],
      "metadata": {
        "id": "sXWk1jSJDbSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam() #tf.keras.optimizers.SGD(momentum=0.9, nesterov=True)\n",
        "\n",
        "accuracy_metric = tf.metrics.SparseCategoricalAccuracy(name='acc')\n",
        "top5_accuracy_metric = tf.metrics.SparseTopKCategoricalAccuracy(k=5, name='top5_acc')\n",
        "resnet50.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n",
        "                 metrics=[accuracy_metric, top5_accuracy_metric])"
      ],
      "metadata": {
        "id": "iXKMRd_qP94M"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting some variables to format the logs:\n",
        "log_begin_red, log_begin_blue, log_begin_green = '\\033[91m', '\\033[94m', '\\033[92m'\n",
        "log_begin_bold, log_begin_underline = '\\033[1m', '\\033[4m'\n",
        "log_end_format = '\\033[0m'\n",
        "\n",
        "class SimpleLogCallback(tf.keras.callbacks.Callback):\n",
        "    \"\"\" Keras callback for simple, denser console logs.\"\"\"\n",
        "\n",
        "    def __init__(self, metrics_dict, num_epochs='?', log_frequency=1,\n",
        "                 metric_string_template='\\033[1m[[name]]\\033[0m = \\033[94m{[[value]]:5.3f}\\033[0m'):\n",
        "        \"\"\"\n",
        "        Initialize the Callback.\n",
        "        :param metrics_dict:            Dictionary containing mappings for metrics names/keys\n",
        "                                        e.g. {\"accuracy\": \"acc\", \"val. accuracy\": \"val_acc\"}\n",
        "        :param num_epochs:              Number of training epochs\n",
        "        :param log_frequency:           Log frequency (in epochs)\n",
        "        :param metric_string_template:  (opt.) String template to print each metric\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.metrics_dict = collections.OrderedDict(metrics_dict)\n",
        "        self.num_epochs = num_epochs\n",
        "        self.log_frequency = log_frequency\n",
        "\n",
        "        # We build a format string to later print the metrics, (e.g. \"Epoch 0/9: loss = 1.00; val-loss = 2.00\")\n",
        "        log_string_template = 'Epoch {0:2}/{1}: '\n",
        "        separator = '; '\n",
        "\n",
        "        i = 2\n",
        "        for metric_name in self.metrics_dict:\n",
        "            templ = metric_string_template.replace('[[name]]', metric_name).replace('[[value]]', str(i))\n",
        "            log_string_template += templ + separator\n",
        "            i += 1\n",
        "\n",
        "        # We remove the \"; \" after the last element:\n",
        "        log_string_template = log_string_template[:-len(separator)]\n",
        "        self.log_string_template = log_string_template\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        print(\"Training: {}start{}\".format(log_begin_red, log_end_format))\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        print(\"Training: {}end{}\".format(log_begin_green, log_end_format))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (epoch - 1) % self.log_frequency == 0 or epoch == self.num_epochs:\n",
        "            values = [logs[self.metrics_dict[metric_name]] for metric_name in self.metrics_dict]\n",
        "            print(self.log_string_template.format(epoch, self.num_epochs, *values))"
      ],
      "metadata": {
        "id": "VZF8ofAMQFvz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Callback to simply log metrics at the end of each epoch (saving space compared to verbose=1):\n",
        "metrics_to_print = collections.OrderedDict([(\"loss\", \"loss\"), \n",
        "                                            (\"v-loss\", \"val_loss\"),\n",
        "                                            (\"acc\", \"acc\"), \n",
        "                                            (\"v-acc\", \"val_acc\"),\n",
        "                                            (\"top5-acc\", \"top5_acc\"), \n",
        "                                            (\"v-top5-acc\", \"val_top5_acc\")])\n",
        "\n",
        "callback_simple_log = SimpleLogCallback(metrics_to_print, \n",
        "                                        num_epochs=num_epochs, log_frequency=2)"
      ],
      "metadata": {
        "id": "6UExG-WgQIX7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = './models/resnet_from_scratch'\n",
        "callbacks = [\n",
        "    # Callback to interrupt the training if the validation loss/metrics stops improving for some epochs:\n",
        "    tf.keras.callbacks.EarlyStopping(patience=8, monitor='val_acc',\n",
        "                                     restore_best_weights=True),\n",
        "    # Callback to log the graph, losses and metrics into TensorBoard:\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=model_dir, histogram_freq=0, write_graph=True),\n",
        "    # Callback to save the model (e.g., every 5 epochs), specifying the epoch and val-loss in the filename:\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        os.path.join(model_dir, 'weights-epoch{epoch:02d}-loss{val_loss:.2f}.h5'), period=5),\n",
        "    # Log callback:\n",
        "    callback_simple_log \n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdIHl3NAQJ-T",
        "outputId": "d746c6ff-6735-40f4-c624-71cee9b1c9eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = resnet50.fit(train_cifar_dataset,  \n",
        "                       epochs=num_epochs, steps_per_epoch=train_steps_per_epoch,\n",
        "                       validation_data=(val_cifar_dataset), validation_steps=val_steps_per_epoch,\n",
        "                       verbose=1, callbacks=callbacks)    # 한 epoch에 7시간 걸려..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "urUcJl93QLgl",
        "outputId": "79aa954d-afc1-4851-9f7d-d2845a6b53d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: \u001b[91mstart\u001b[0m\n",
            "Epoch 1/100\n",
            "   7/3125 [..............................] - ETA: 7:01:12 - loss: 17.5873 - acc: 0.0089 - top5_acc: 0.0357"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c9336b64ff8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_cifar_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                        verbose=1, callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(3, 2, figsize=(15, 10), sharex='col') # add parameter `sharey='row'` for a more direct comparison\n",
        "ax[0, 0].set_title(\"loss\")\n",
        "ax[0, 1].set_title(\"val-loss\")\n",
        "ax[1, 0].set_title(\"acc\")\n",
        "ax[1, 1].set_title(\"val-acc\")\n",
        "ax[2, 0].set_title(\"top5-acc\")\n",
        "ax[2, 1].set_title(\"val-top5-acc\")\n",
        "\n",
        "ax[0, 0].plot(history.history['loss'])\n",
        "ax[0, 1].plot(history.history['val_loss'])\n",
        "ax[1, 0].plot(history.history['acc'])\n",
        "ax[1, 1].plot(history.history['val_acc'])\n",
        "ax[2, 0].plot(history.history['top5_acc'])\n",
        "ax[2, 1].plot(history.history['val_top5_acc'])"
      ],
      "metadata": {
        "id": "BkZdP9BNEAZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = max(history.history['val_acc']) * 100\n",
        "best_val_top5 = max(history.history['val_top5_acc']) * 100\n",
        "\n",
        "print('Best val acc:  {:2.2f}%'.format(best_val_acc))\n",
        "print('Best val top5: {:2.2f}%'.format(best_val_top5))"
      ],
      "metadata": {
        "id": "a-nHTUAIEHCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-LY4fz66EJGJ"
      }
    }
  ]
}